from invert_index import Invert_Index
import config
import json
import numpy as np
import pandas as pd
from file_reader import File_Reader
from file_writer import File_Writer

class VSM:
    def __init__(self):
        self.ii = Invert_Index()
        self.fr = File_Reader()
        self.fw = File_Writer()
        self.pl_path = config.posting_list_path
        self.pl = {}
        self.hash_dict = self.ii.posting_list()

    def get_termid(self, query_list):
        '''
        @usage: according user query, find term id from dictionary
        @arg query_list: list of user query
        @return: list of term id, example user query for [chair, desk], return [24, 45]
        '''
        #step 1, find index of current user query
        term_id = []
        for query in query_list:
            try:
                term_id.append(self.hash_dict.keys()[self.hash_dict.values().index(query)])
            except:
                pass
        return term_id

    def get_docs(self, term_id):
        '''
        @usage: according to query index, get related documents
        @arg: term_id, id of user query terms
        @return: dict of document location, {24: [doc1, doc5, doc7], 45: [doc8, dic11, doc22]}
        '''
        with open(self.pl_path) as pl_file:
            self.pl = json.load(pl_file)
        term_location = {}
        for term in term_id:
            term_location[term] = self.pl[str(term)]
        return term_location, term_id

    def build_query_vector(self, term_id):
        '''
        @usage: build query vector
        @arg term_id: list of terms id
        @return: pandas data frame 1 row * n columns
        '''
        #build query vector
        #init a pandas data frame
        query_vector = pd.DataFrame(index = [1], columns = range(0, len(self.hash_dict)-1))
        query_vector = query_vector.fillna(0)
        for term in term_id:
            query_vector.xs(1, copy = False)[term_id] = 1
        return query_vector
    def simple_vector_space(self, term_location, term_id):
        '''
        @usage: build simple vector space model
        @arg term_location: dict of term id and term docs, for example {1: [doc1, doc3]}
        @arg term_id: list of term id
        @return: dict of score
        '''
        #since some term may exist in multiple docs, remove overlap docs
        docs = []
        for term in term_id:
            docs.extend(term_location[term])
        docs = list(set(docs))
        #init a dataframe, rows are docs, columns are terms
        df = pd.DataFrame(index = docs, columns = range(0, len(self.hash_dict)))
        df = df.fillna(0)
        #init a dictionary to store doc length
        doc_len = {}
        for current_doc in docs:
            content = self.fr.read_file(current_doc)
            content = self.clean(content)
            #add into doc_len dict, for furture normalize
            doc_len[current_doc] = len(content.split())
            for term in content.split():
                #get term_id by term
                term_id = self.hash_dict.keys()[self.hash_dict.values().index(term)]
                #add current dataframe
                df.xs(current_doc, copy = False)[term_id] += 1
        #insert a line into matrix indicate document frequency
        document_frequency = []
        for i in range(0, len(self.hash_table)-1):
            #if current term >=1 means current term appear in doc
            temp_df = list(df.ix[:,i] >= 1)
            document_frequency.append(sum(temp_df))
        print document_frequency

    def clean(self, content):
        '''
        @usage: clean content, remove
        @arg content: content of document
        @return: cleaned content
        '''
        punc = set(string.punctuation)







vsm = VSM()
term_id = vsm.get_termid(['a', 'chair'])
term_location, term_id = get_docs = vsm.get_docs(term_id)
vsm.simple_vector_space(term_location, term_id)
